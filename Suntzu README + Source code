  mkdir Suntzu
   cd Suntzu
nano suntzu.py
#Paste the following code into suntzu.py and save the file:


#!/usr/bin/env python3

import sys
import requests
from bs4 import BeautifulSoup
import urllib.parse

SEARCH_ENGINES = {
    'Google': 'https://www.google.com/search',
    'Bing': 'https://www.bing.com/search',
    'DuckDuckGo': 'https://duckduckgo.com/',
    'Yandex': 'https://yandex.com/search/'
}

FORUM_SEARCH_TERMS = [
    'military', 'troops', 'cyber attack', 'forces', 'invade',
    'invasion', 'regime', 'riots', 'civil unrest'
]

SUBREDDITS = {
    'North Korea': 'r/NorthKorea',
    'Russia': 'r/Russia',
    'China': 'r/China',
    'Iran': 'r/Iran'
}

def perform_search(query, engine):
    """Perform a search on the specified search engine."""
    search_query = f"{query} military news"
    headers = {
        'User-Agent': 'Suntzu CLI Tool'
    }
    params = {'q': urllib.parse.quote(search_query)}

    if engine == 'DuckDuckGo':
        params = {'q': search_query}
    elif engine == 'Yandex':
        params = {'text': search_query}

    try:
        response = requests.get(SEARCH_ENGINES[engine], headers=headers, params=params)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        headlines = []

        if engine == 'Google':
            for item in soup.find_all('h3'):
                title = item.get_text()
                parent_a = item.find_parent('a')
                if parent_a and parent_a.has_attr('href'):
                    url = 'https://www.google.com' + parent_a['href']
                else:
                    url = 'No URL available'
                headlines.append({'title': title, 'url': url})

        elif engine == 'Bing':
            for item in soup.find_all('h2'):
                title = item.get_text()
                parent_a = item.find_parent('a')
                if parent_a and parent_a.has_attr('href'):
                    url = parent_a['href']
                else:
                    url = 'No URL available'
                headlines.append({'title': title, 'url': url})

        elif engine == 'DuckDuckGo':
            for item in soup.find_all('a', class_='result__a'):
                title = item.get_text()
                url = item['href']
                headlines.append({'title': title, 'url': url})

        elif engine == 'Yandex':
            for item in soup.find_all('h2', class_='organic__title'):
                title = item.get_text()
                parent_a = item.find_parent('a')
                if parent_a and parent_a.has_attr('href'):
                    url = parent_a['href']
                else:
                    url = 'No URL available'
                headlines.append({'title': title, 'url': url})

        return headlines

    except requests.exceptions.RequestException as e:
        print(f"An error occurred while querying {engine}: {e}")
        return []

def perform_forum_search(query):
    """Search for military-related forum posts using Google."""
    headlines = []

    for term in FORUM_SEARCH_TERMS:
        search_query = f"{query} {term}"
        headers = {
            'User-Agent': 'Suntzu CLI Tool'
        }
        params = {'q': urllib.parse.quote(search_query)}

        try:
            response = requests.get(SEARCH_ENGINES['Google'], headers=headers, params=params)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')

            for item in soup.find_all('h3'):
                title = item.get_text()
                parent_a = item.find_parent('a')
                if parent_a and parent_a.has_attr('href'):
                    url = 'https://www.google.com' + parent_a['href']
                else:
                    url = 'No URL available'
                headlines.append({'title': title, 'url': url})

        except requests.exceptions.RequestException as e:
            print(f"An error occurred while querying forums for term '{term}': {e}")

    return headlines

def perform_reddit_search(query):
    """Search for Reddit posts related to military topics."""
    reddit_results = []

    subreddit = SUBREDDITS.get(query, None)
    if subreddit:
        search_query = f"{query} military"
        reddit_url = f"https://www.google.com/search?q=site:reddit.com+{search_query}"

        headers = {
            'User-Agent': 'Suntzu CLI Tool'
        }
        params = {'q': urllib.parse.quote(search_query)}

        try:
            response = requests.get(reddit_url, headers=headers, params=params)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')

            for item in soup.find_all('h3'):
                title = item.get_text()
                parent_a = item.find_parent('a')
                if parent_a and parent_a.has_attr('href'):
                    url = parent_a['href']
                    # Make sure URL is from Reddit
                    if 'reddit.com' in url:
                        reddit_results.append({'title': title, 'url': url})

        except requests.exceptions.RequestException as e:
            print(f"An error occurred while querying Reddit: {e}")

    return reddit_results

def display_results(results):
    """Display search results in the terminal."""
    if not results:
        print("No results found.")
        return

    for result in results:
        print(f"Title: {result['title']}")
        print(f"URL: {result['url']}\n")
        print("-" * 80)

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: suntzuget <subject>")
        sys.exit(1)

    subject = sys.argv[1]
    all_headlines = []

    # Perform main search on all search engines
    for engine in SEARCH_ENGINES.keys():
        print(f"Querying {engine}...")
        headlines = perform_search(subject, engine)
        all_headlines.extend(headlines)

    # Perform additional searches for forum posts
    print("Querying forums...")
    forum_headlines = perform_forum_search(subject)
    all_headlines.extend(forum_headlines)

    # Perform Reddit search if applicable
    print("Querying Reddit...")
    reddit_headlines = perform_reddit_search(subject)
    all_headlines.extend(reddit_headlines)

    # Remove duplicate headlines and sort them by title
    unique_headlines = {h['title']: h for h in all_headlines}.values()
    sorted_headlines = sorted(unique_headlines, key=lambda x: x['title'])

    display_results(sorted_headlines)

 






Be root user before running the install script, sudo su or be root before running it, it needs execution permissions. you dont have to be root to use the tool, just to install it with the script.
#Make the file executable
chmod +x suntzu.py

#Create a Symlink for suntzuget:
sudo ln -s $(pwd)/suntzu.py /usr/local/bin/suntzuget

#To use the Suntzu CLI tool, simply run:
#suntzuget <subject>
suntzuget North Korea
#You do not need to use _ between search words, example suntzuget North_Korea
#You can simply type "suntzuget North Korea"
This is not a professional research tool, it is a tool designed for terminal junkies who love the CLI, it pulls headlines and is more of an interesting tool to mess around with, designed for military nerds and terminal junkies as a hobby tool
