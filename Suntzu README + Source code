  mkdir Suntzu
   cd Suntzu
nano suntzu.py
#Paste the following code into suntzu.py and save the file:



#!/usr/bin/env python3

import sys
import requests
from bs4 import BeautifulSoup
import urllib.parse
import webbrowser

SEARCH_ENGINES = {
    'Google': 'https://www.google.com/search',
    'Bing': 'https://www.bing.com/search',
    'DuckDuckGo': 'https://duckduckgo.com/',
    'Yandex': 'https://yandex.com/search/'
}

FORUM_SEARCH_TERMS = [
    'military', 'troops', 'cyber attack', 'forces', 'invade',
    'invasion', 'regime', 'riots', 'civil unrest'
]

SUBREDDITS = {
    'North Korea': 'r/NorthKorea',
    'Russia': 'r/Russia',
    'China': 'r/China',
    'Iran': 'r/Iran'
}

def perform_search(query, engine):
    """Perform a search on the specified search engine."""
    search_query = f"{query} military news"
    headers = {
        'User-Agent': 'Suntzu CLI Tool'
    }
    params = {'q': urllib.parse.quote(search_query)}

    if engine == 'DuckDuckGo':
        params = {'q': search_query}
    elif engine == 'Yandex':
        params = {'text': search_query}

    try:
        response = requests.get(SEARCH_ENGINES[engine], headers=headers, params=params)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        headlines = []

        if engine == 'Google':
            for item in soup.find_all('h3'):
                title = item.get_text()
                parent_a = item.find_parent('a')
                url = 'No URL available'
                if parent_a and parent_a.has_attr('href'):
                    url = 'https://www.google.com' + parent_a['href']
                date = item.find_next_sibling('span', class_='f')  # Example for date
                date_text = date.get_text() if date else 'No date available'
                headlines.append({'title': title, 'url': url, 'date': date_text})

        elif engine == 'Bing':
            for item in soup.find_all('h2'):
                title = item.get_text()
                parent_a = item.find_parent('a')
                url = parent_a['href'] if parent_a and parent_a.has_attr('href') else 'No URL available'
                date = item.find_next_sibling('span', class_='b_date')  # Example for date
                date_text = date.get_text() if date else 'No date available'
                headlines.append({'title': title, 'url': url, 'date': date_text})

        elif engine == 'DuckDuckGo':
            for item in soup.find_all('a', class_='result__a'):
                title = item.get_text()
                url = item['href']
                date = 'No date available'  # DuckDuckGo may not provide date
                headlines.append({'title': title, 'url': url, 'date': date})

        elif engine == 'Yandex':
            for item in soup.find_all('h2', class_='organic__title'):
                title = item.get_text()
                parent_a = item.find_parent('a')
                url = parent_a['href'] if parent_a and parent_a.has_attr('href') else 'No URL available'
                date = item.find_next_sibling('span', class_='date')  # Example for date
                date_text = date.get_text() if date else 'No date available'
                headlines.append({'title': title, 'url': url, 'date': date_text})

        return headlines

    except requests.exceptions.RequestException as e:
        print(f"An error occurred while querying {engine}: {e}")
        return []

def perform_forum_search(query):
    """Search for military-related forum posts using Google."""
    headlines = []

    for term in FORUM_SEARCH_TERMS:
        search_query = f"{query} {term}"
        headers = {
            'User-Agent': 'Suntzu CLI Tool'
        }
        params = {'q': urllib.parse.quote(search_query)}

        try:
            response = requests.get(SEARCH_ENGINES['Google'], headers=headers, params=params)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')

            for item in soup.find_all('h3'):
                title = item.get_text()
                parent_a = item.find_parent('a')
                url = 'https://www.google.com' + parent_a['href'] if parent_a and parent_a.has_attr('href') else 'No URL available'
                date = item.find_next_sibling('span', class_='f')  # Example for date
                date_text = date.get_text() if date else 'No date available'
                headlines.append({'title': title, 'url': url, 'date': date_text})

        except requests.exceptions.RequestException as e:
            print(f"An error occurred while querying forums for term '{term}': {e}")

    return headlines

def perform_reddit_search(query):
    """Search for Reddit posts related to military topics."""
    reddit_results = []

    subreddit = SUBREDDITS.get(query, None)
    if subreddit:
        search_query = f"{query} military"
        reddit_url = f"https://www.google.com/search?q=site:reddit.com+{search_query}"

        headers = {
            'User-Agent': 'Suntzu CLI Tool'
        }
        params = {'q': urllib.parse.quote(search_query)}

        try:
            response = requests.get(reddit_url, headers=headers, params=params)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')

            for item in soup.find_all('h3'):
                title = item.get_text()
                parent_a = item.find_parent('a')
                url = parent_a['href'] if parent_a and parent_a.has_attr('href') else 'No URL available'
                if 'reddit.com' in url:
                    date = 'No date available'  # Reddit date extraction not available
                    reddit_results.append({'title': title, 'url': url, 'date': date})

        except requests.exceptions.RequestException as e:
            print(f"An error occurred while querying Reddit: {e}")

    return reddit_results

def display_results(results):
    """Display search results in the terminal."""
    if not results:
        print("No results found.")
        return

    for result in results:
        print(f"Title: {result['title']}")
        print(f"URL: {result['url']}")
        print(f"Date: {result['date']}")
        print("-" * 80)
        # Make URL clickable in some terminals
        if result['url'] != 'No URL available':
            webbrowser.open(result['url'])

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: suntzuget <subject>")
        sys.exit(1)

    subject = sys.argv[1]
    all_headlines = []

    # Perform main search on all search engines
    for engine in SEARCH_ENGINES.keys():
        print(f"Querying {engine}...")
        headlines = perform_search(subject, engine)
        all_headlines.extend(headlines)

    # Perform additional searches for forum posts
    print("Querying forums...")
    forum_headlines = perform_forum_search(subject)
    all_headlines.extend(forum_headlines)

    # Perform Reddit search if applicable
    print("Querying Reddit...")
    reddit_headlines = perform_reddit_search(subject)
    all_headlines.extend(reddit_headlines)

    # Remove duplicate headlines and sort them by title
    unique_headlines = {h['title']: h for h in all_headlines}.values()
    sorted_headlines = sorted(unique_headlines, key=lambda x: x['title'])

    display_results(sorted_headlines)









#Make the file executable
chmod +x suntzu.py

#Create a Symlink for suntzuget:
sudo ln -s $(pwd)/suntzu.py /usr/local/bin/suntzuget

#To use the Suntzu CLI tool, simply run:
#suntzuget <subject>
suntzuget North Korea
#You do not need to use _ between search words, example suntzuget North_Korea
#You can simply type "suntzuget North Korea"

